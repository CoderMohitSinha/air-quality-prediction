{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义了生成训练样本和验证集的两个函数，该 .ipynb 文件为测试样例，两个函数已经放在了 `seq2seq/seq2seq_data_util.py` 中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "疑问：\n",
    "- 每一次生成数据的特征之间的顺序如何保持一致？\n",
    "- y_train 的特征排序如何保持和 y_eva 一致？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在生成数据时候需要考虑的因素\n",
    "    - 训练数据和验证数据是分开产生的\n",
    "    - 验证数据中不存在 NAN，但是训练数据中存在 NAN。如何保证生成的训练数据没有 NAN\n",
    "    - 数据的生成是不是严格按照“天”的概念\n",
    "        - 验证集\n",
    "            - 验证集一定严格按照“天”取生成\n",
    "        - 训练集\n",
    "            - 可以是严格按照“天”去生成，这样训练样本合理，但是数量少\n",
    "            - 也可以是宽松的按照每一个小时去生成，这样训练样本的数量会更多\n",
    "            - 也可以在训练的过程中综合使用上述两种训练集生成策略\n",
    "    - 特征的灵活选择\n",
    "        - 应设计生成训练集和验证集的两个函数，使之可以灵活的生成包含各种特征的数据\n",
    "            - 站点\n",
    "                - 所有站点数据\n",
    "                - 个别站点数据\n",
    "            - 天气/空气质量\n",
    "                - 可以只包含空气质量\n",
    "                - 可以包含空气质量和天气\n",
    "            - 详细特征\n",
    "                - 如天气中的几个特征和空气质量的几个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dev_set(station_list, X_aq_list, y_aq_list, X_meo_list=None, pre_days=5):\n",
    "    '''\n",
    "   \n",
    "    Args:\n",
    "        station_list : a list of used stations.\n",
    "        X_aq_list : a list of used aq features as input.\n",
    "        y_aq_list : a list of used aq features as output. \n",
    "        X_meo_list : a list of used meo features.\n",
    "        \n",
    "    station_list = ['dongsi_aq','tiantan_aq','guanyuan_aq','wanshouxigong_aq','aotizhongxin_aq',\n",
    "                'nongzhanguan_aq','wanliu_aq','beibuxinqu_aq','zhiwuyuan_aq','fengtaihuayuan_aq',\n",
    "                'yungang_aq','gucheng_aq','fangshan_aq','daxing_aq','yizhuang_aq','tongzhou_aq',\n",
    "                'shunyi_aq','pingchang_aq','mentougou_aq','pinggu_aq','huairou_aq','miyun_aq',\n",
    "                'yanqin_aq','dingling_aq','badaling_aq','miyunshuiku_aq','donggaocun_aq',\n",
    "                'yongledian_aq','yufa_aq','liulihe_aq','qianmen_aq','yongdingmennei_aq',\n",
    "                'xizhimenbei_aq','nansanhuan_aq','dongsihuan_aq']            \n",
    "    X_aq_list = [\"PM2.5\",\"PM10\",\"O3\",\"CO\",\"SO2\",\"NO2\"]  \n",
    "    y_aq_list = [\"PM2.5\",\"PM10\",\"O3\"]\n",
    "    X_meo_list = [\"temperature\",\"pressure\",\"humidity\",\"direction\",\"speed/kph\"]\n",
    "    '''\n",
    "    aq_dev = pd.read_csv(\"data/aq_dev_data.csv\")\n",
    "    meo_dev = pd.read_csv(\"data/meo_dev_data.csv\")\n",
    "    \n",
    "    dev_df = pd.concat([aq_dev, meo_dev], axis=1)\n",
    "    \n",
    "    # step 1 : keep all features about the stations\n",
    "    station_filters = []\n",
    "    for station in station_list : \n",
    "        station_filter = [index for index in dev_df.columns if station in index]\n",
    "        station_filters += station_filter\n",
    "    \n",
    "    # step 2 : filter of X features\n",
    "    X_feature_filters = []\n",
    "    if X_meo_list :\n",
    "        X_features = X_aq_list + X_meo_list\n",
    "    else :\n",
    "        X_features = X_aq_list\n",
    "        \n",
    "    for i in station_filters : \n",
    "        if i.split(\"_\")[-1] in X_features :\n",
    "            X_feature_filters += [i]\n",
    "            \n",
    "    X_feature_filters.sort()  # 排序，保证训练集和验证集中的特征的顺序一致\n",
    "    X_df = dev_df[X_feature_filters]\n",
    "    \n",
    "    # step 3 : filter of y features\n",
    "    y_feature_filters = []\n",
    "    y_features = y_aq_list\n",
    "    \n",
    "    for i in station_filters : \n",
    "        if i.split(\"_\")[-1] in y_features :\n",
    "            y_feature_filters += [i]\n",
    "    \n",
    "    y_feature_filters.sort()  # 排序，保证训练集和验证集中的特征的顺序一致\n",
    "    y_df = dev_df[y_feature_filters]   \n",
    "    \n",
    "    # step 4 : 按天生成数据\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "    \n",
    "    m = int(np.floor(X_df.shape[0] / 24 + 1 - (pre_days + 2)))\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        X_start_index = 24 * i\n",
    "        X_end_index = 24 * (i + pre_days) - 1\n",
    "\n",
    "        y_start_index = 24 * (i + pre_days)\n",
    "        y_end_index = 24 * (i + pre_days + 2) - 1\n",
    "\n",
    "\n",
    "        X = X_df.loc[X_start_index : X_end_index]\n",
    "        y = y_df.loc[y_start_index : y_end_index]\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        X = np.expand_dims(X, axis=0)\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "\n",
    "        X_df_list.append(X)\n",
    "        y_df_list.append(y)\n",
    "\n",
    "    X_dev_batch = np.concatenate(X_df_list, axis=0)\n",
    "    y_dev_batch = np.concatenate(y_df_list, axis=0)\n",
    "    \n",
    "    return X_dev_batch, y_dev_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_set(station_list, X_aq_list, y_aq_list, X_meo_list=None, use_day=True, pre_days=5, batch_size=32):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "        station_list : a list of used stations.\n",
    "        X_aq_list : a list of used aq features as input.\n",
    "        y_aq_list : a list of used aq features as output. \n",
    "        X_meo_list : a list of used meo features.\n",
    "        use_day : bool, True to just use 0-24 h days.\n",
    "        pre_days : use pre_days history days to predict.\n",
    "        batch_size\n",
    "        \n",
    "    station_list = ['dongsi_aq','tiantan_aq','guanyuan_aq','wanshouxigong_aq','aotizhongxin_aq',\n",
    "                'nongzhanguan_aq','wanliu_aq','beibuxinqu_aq','zhiwuyuan_aq','fengtaihuayuan_aq',\n",
    "                'yungang_aq','gucheng_aq','fangshan_aq','daxing_aq','yizhuang_aq','tongzhou_aq',\n",
    "                'shunyi_aq','pingchang_aq','mentougou_aq','pinggu_aq','huairou_aq','miyun_aq',\n",
    "                'yanqin_aq','dingling_aq','badaling_aq','miyunshuiku_aq','donggaocun_aq',\n",
    "                'yongledian_aq','yufa_aq','liulihe_aq','qianmen_aq','yongdingmennei_aq',\n",
    "                'xizhimenbei_aq','nansanhuan_aq','dongsihuan_aq']            \n",
    "    X_aq_list = [\"PM2.5\",\"PM10\",\"O3\",\"CO\",\"SO2\",\"NO2\"]  \n",
    "    y_aq_list = [\"PM2.5\",\"PM10\",\"O3\"]\n",
    "    X_meo_list = [\"temperature\",\"pressure\",\"humidity\",\"direction\",\"speed/kph\"]\n",
    "    '''\n",
    "    \n",
    "    aq_train = pd.read_csv(\"data/aq_train_data.csv\")\n",
    "    meo_train = pd.read_csv(\"data/meo_train_data.csv\")\n",
    "    \n",
    "    dev_df = pd.concat([aq_train, meo_train], axis=1)\n",
    "    \n",
    "    # step 1 : keep all features about the stations\n",
    "    station_filters = []\n",
    "    for station in station_list : \n",
    "        station_filter = [index for index in dev_df.columns if station in index]\n",
    "        station_filters += station_filter\n",
    "    \n",
    "    # step 2 : filter of X features\n",
    "    X_feature_filters = []\n",
    "    if X_meo_list :\n",
    "        X_features = X_aq_list + X_meo_list\n",
    "    else :\n",
    "        X_features = X_aq_list\n",
    "        \n",
    "    for i in station_filters : \n",
    "        if i.split(\"_\")[-1] in X_features :\n",
    "            X_feature_filters += [i]\n",
    "            \n",
    "    X_feature_filters.sort()  # 排序，保证训练集和验证集中的特征的顺序一致\n",
    "    X_df = dev_df[X_feature_filters]\n",
    "    \n",
    "    # step 3 : filter of y features\n",
    "    y_feature_filters = []\n",
    "    y_features = y_aq_list\n",
    "    \n",
    "    for i in station_filters : \n",
    "        if i.split(\"_\")[-1] in y_features :\n",
    "            y_feature_filters += [i]\n",
    "    \n",
    "    y_feature_filters.sort()  # 排序，保证训练集和验证集中的特征的顺序一致\n",
    "    y_df = dev_df[y_feature_filters]\n",
    "    \n",
    "    # step 4 : generate training batch\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "    \n",
    "    max_start_points = X_df.shape[0] - (pre_days + 2) * 24\n",
    "    if use_day : \n",
    "        total_start_points = range(0, max_start_points, 24)\n",
    "    else :\n",
    "        total_start_points = range(0, max_start_points, 1)\n",
    "    \n",
    "    for i in range(batch_size):       \n",
    "        flag = True        \n",
    "        while flag :\n",
    "            X_start_index = int(np.random.choice(total_start_points, 1, replace = False))\n",
    "            X_end_index = X_start_index + pre_days * 24 - 1\n",
    "\n",
    "            y_start_index = X_end_index + 1\n",
    "            y_end_index = X_end_index + 48\n",
    "    \n",
    "            # print(X_start_index, X_end_index, y_start_index, y_end_index)\n",
    "\n",
    "            X = X_df.loc[X_start_index : X_end_index]\n",
    "            y = y_df.loc[y_start_index : y_end_index]\n",
    "\n",
    "            # 判断是不是有 NAN\n",
    "            if pd.isnull(X).any().any() :\n",
    "                pass\n",
    "            else :     \n",
    "                X = np.array(X)\n",
    "                y = np.array(y)\n",
    "                X = np.expand_dims(X, axis=0)\n",
    "                y = np.expand_dims(y, axis=0)\n",
    "                X_df_list.append(X)\n",
    "                y_df_list.append(y)\n",
    "                flag = False\n",
    "\n",
    "    X_train_batch = np.concatenate(X_df_list, axis=0)\n",
    "    y_train_batch = np.concatenate(y_df_list, axis=0)\n",
    "    \n",
    "    return X_train_batch, y_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_list = ['dongsi_aq','tiantan_aq','guanyuan_aq','wanshouxigong_aq','aotizhongxin_aq',\n",
    "            'nongzhanguan_aq','wanliu_aq','beibuxinqu_aq','zhiwuyuan_aq','fengtaihuayuan_aq',\n",
    "            'yungang_aq','gucheng_aq','fangshan_aq','daxing_aq','yizhuang_aq','tongzhou_aq',\n",
    "            'shunyi_aq','pingchang_aq','mentougou_aq','pinggu_aq','huairou_aq','miyun_aq',\n",
    "            'yanqin_aq','dingling_aq','badaling_aq','miyunshuiku_aq','donggaocun_aq',\n",
    "            'yongledian_aq','yufa_aq','liulihe_aq','qianmen_aq','yongdingmennei_aq',\n",
    "            'xizhimenbei_aq','nansanhuan_aq','dongsihuan_aq']            \n",
    "X_aq_list = [\"PM2.5\",\"PM10\",\"O3\",\"CO\",\"SO2\",\"NO2\"]  \n",
    "y_aq_list = [\"PM2.5\",\"PM10\",\"O3\"]\n",
    "X_meo_list = [\"temperature\",\"pressure\",\"humidity\",\"direction\",\"speed/kph\"]\n",
    "use_day=True\n",
    "pre_days=5\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = generate_dev_set(station_list, X_aq_list, y_aq_list, X_meo_list, pre_days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 120, 385) (17, 48, 105)\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = generate_training_set(station_list, X_aq_list, y_aq_list, X_meo_list, pre_days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 120, 385) (32, 48, 105)\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "- 20180425 v0\n",
    "    - 完成了两个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
