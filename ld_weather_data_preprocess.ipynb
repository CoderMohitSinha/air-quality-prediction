{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from utils.weather_data_util import load_ld_grid_meo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 首先加载使用到的 meo 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_stations = {'BL0': 'london_grid_409',\n",
    " 'BX1': 'london_grid_472',\n",
    " 'BX9': 'london_grid_472',\n",
    " 'CD1': 'london_grid_388',\n",
    " 'CD9': 'london_grid_409',\n",
    " 'CR8': 'london_grid_408',\n",
    " 'CT2': 'london_grid_409',\n",
    " 'CT3': 'london_grid_409',\n",
    " 'GB0': 'london_grid_451',\n",
    " 'GN0': 'london_grid_451',\n",
    " 'GN3': 'london_grid_451',\n",
    " 'GR4': 'london_grid_451',\n",
    " 'GR9': 'london_grid_430',\n",
    " 'HR1': 'london_grid_368',\n",
    " 'HV1': 'london_grid_472',\n",
    " 'KC1': 'london_grid_388',\n",
    " 'KF1': 'london_grid_388',\n",
    " 'LH0': 'london_grid_346',\n",
    " 'LW2': 'london_grid_430',\n",
    " 'MY7': 'london_grid_388',\n",
    " 'RB7': 'london_grid_452',\n",
    " 'ST5': 'london_grid_408',\n",
    " 'TD5': 'london_grid_366',\n",
    " 'TH4': 'london_grid_430'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bj_meo_stations : meo_station as key and df as value \n",
    "bj_grid_meo_dataset, stations, bj_meo_stations = load_ld_grid_meo_data(near_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BX1_temperature</th>\n",
       "      <th>BX1_pressure</th>\n",
       "      <th>BX1_humidity</th>\n",
       "      <th>BX1_wind_direction</th>\n",
       "      <th>BX1_wind_speed/kph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>5.52</td>\n",
       "      <td>1020.08</td>\n",
       "      <td>92.83</td>\n",
       "      <td>225.18</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>5.64</td>\n",
       "      <td>1018.89</td>\n",
       "      <td>90.95</td>\n",
       "      <td>222.71</td>\n",
       "      <td>16.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>5.75</td>\n",
       "      <td>1017.69</td>\n",
       "      <td>89.08</td>\n",
       "      <td>220.60</td>\n",
       "      <td>17.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>5.87</td>\n",
       "      <td>1016.50</td>\n",
       "      <td>87.20</td>\n",
       "      <td>218.77</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>6.00</td>\n",
       "      <td>1015.56</td>\n",
       "      <td>87.46</td>\n",
       "      <td>216.84</td>\n",
       "      <td>19.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BX1_temperature  BX1_pressure  BX1_humidity  \\\n",
       "time                                                               \n",
       "2017-01-01 00:00:00             5.52       1020.08         92.83   \n",
       "2017-01-01 01:00:00             5.64       1018.89         90.95   \n",
       "2017-01-01 02:00:00             5.75       1017.69         89.08   \n",
       "2017-01-01 03:00:00             5.87       1016.50         87.20   \n",
       "2017-01-01 04:00:00             6.00       1015.56         87.46   \n",
       "\n",
       "                     BX1_wind_direction  BX1_wind_speed/kph  \n",
       "time                                                         \n",
       "2017-01-01 00:00:00              225.18               14.84  \n",
       "2017-01-01 01:00:00              222.71               16.06  \n",
       "2017-01-01 02:00:00              220.60               17.31  \n",
       "2017-01-01 03:00:00              218.77               18.58  \n",
       "2017-01-01 04:00:00              216.84               19.03  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_meo_stations['BX1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bj_meo_stations.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 重复值分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 识别重复值的数量，并将重复值去掉\n",
    "- meo 数据中没有重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq 重复数量 : 0\n",
      "liulihe_aq 重复数量 : 0\n",
      "beibuxinqu_aq 重复数量 : 0\n",
      "badaling_aq 重复数量 : 0\n",
      "shunyi_aq 重复数量 : 0\n",
      "yongdingmennei_aq 重复数量 : 0\n",
      "fangshan_aq 重复数量 : 0\n",
      "wanliu_aq 重复数量 : 0\n",
      "qianmen_aq 重复数量 : 0\n",
      "donggaocun_aq 重复数量 : 0\n",
      "gucheng_aq 重复数量 : 0\n",
      "nansanhuan_aq 重复数量 : 0\n",
      "guanyuan_aq 重复数量 : 0\n",
      "dongsihuan_aq 重复数量 : 0\n",
      "nongzhanguan_aq 重复数量 : 0\n",
      "yizhuang_aq 重复数量 : 0\n",
      "yanqin_aq 重复数量 : 0\n",
      "miyun_aq 重复数量 : 0\n",
      "mentougou_aq 重复数量 : 0\n",
      "yufa_aq 重复数量 : 0\n",
      "aotizhongxin_aq 重复数量 : 0\n",
      "wanshouxigong_aq 重复数量 : 0\n",
      "zhiwuyuan_aq 重复数量 : 0\n",
      "tiantan_aq 重复数量 : 0\n",
      "huairou_aq 重复数量 : 0\n",
      "daxing_aq 重复数量 : 0\n",
      "miyunshuiku_aq 重复数量 : 0\n",
      "xizhimenbei_aq 重复数量 : 0\n",
      "tongzhou_aq 重复数量 : 0\n",
      "yungang_aq 重复数量 : 0\n",
      "dingling_aq 重复数量 : 0\n",
      "fengtaihuayuan_aq 重复数量 : 0\n",
      "pingchang_aq 重复数量 : 0\n",
      "yongledian_aq 重复数量 : 0\n",
      "pinggu_aq 重复数量 : 0\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    \n",
    "    df = bj_meo_stations[station].copy()\n",
    "    length = df.shape[0]\n",
    "    order = range(length)\n",
    "    df['order'] = pd.Series(order, index=df.index)    \n",
    "    \n",
    "    \n",
    "    df[\"time\"] = df.index\n",
    "    df.set_index(\"order\", inplace=True)\n",
    "    \n",
    "    length_1 = df.shape[0]\n",
    "    # print(\"重复值去除之前，共有数据数量\", df.shape[0])\n",
    "    \n",
    "    used_times = []\n",
    "    for index in df.index :\n",
    "        time = df.loc[index][\"time\"]\n",
    "        if time not in used_times :\n",
    "            used_times.append(time)\n",
    "        else : \n",
    "            df.drop([index], inplace=True)\n",
    "\n",
    "    length_2 = df.shape[0]\n",
    "    delta = length_1 - length_2\n",
    "    # print(\"重复值去除之后，共有数据数量\", df.shape[0])\n",
    "    print(\"%s 重复数量 : %d\" %(station, delta))\n",
    "    \n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    bj_meo_stations[station] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 缺失值分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 局部缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断有没有局部缺失：没有局部缺失！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq False\n",
      "liulihe_aq False\n",
      "beibuxinqu_aq False\n",
      "badaling_aq False\n",
      "shunyi_aq False\n",
      "yongdingmennei_aq False\n",
      "fangshan_aq False\n",
      "wanliu_aq False\n",
      "qianmen_aq False\n",
      "donggaocun_aq False\n",
      "gucheng_aq False\n",
      "nansanhuan_aq False\n",
      "guanyuan_aq False\n",
      "dongsihuan_aq False\n",
      "nongzhanguan_aq False\n",
      "yizhuang_aq False\n",
      "yanqin_aq False\n",
      "miyun_aq False\n",
      "mentougou_aq False\n",
      "yufa_aq False\n",
      "aotizhongxin_aq False\n",
      "wanshouxigong_aq False\n",
      "zhiwuyuan_aq False\n",
      "tiantan_aq False\n",
      "huairou_aq False\n",
      "daxing_aq False\n",
      "miyunshuiku_aq False\n",
      "xizhimenbei_aq False\n",
      "tongzhou_aq False\n",
      "yungang_aq False\n",
      "dingling_aq False\n",
      "fengtaihuayuan_aq False\n",
      "pingchang_aq False\n",
      "yongledian_aq False\n",
      "pinggu_aq False\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys():\n",
    "    df = bj_meo_stations[station]\n",
    "    print(station, pd.isnull(df).any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 整体缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计缺失小时的连续值\n",
    "- 如果一个缺失小时在一个长度小于等于5小时的缺失时段内，就进行补全\n",
    "- 如果超过5小时，就舍弃，将全部值补成 NAN，**这也是整个表中唯一可能出现 NAN 的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq 缺失时间节点数量是 121\n",
      "liulihe_aq 缺失时间节点数量是 121\n",
      "beibuxinqu_aq 缺失时间节点数量是 121\n",
      "badaling_aq 缺失时间节点数量是 121\n",
      "shunyi_aq 缺失时间节点数量是 121\n",
      "yongdingmennei_aq 缺失时间节点数量是 121\n",
      "fangshan_aq 缺失时间节点数量是 121\n",
      "wanliu_aq 缺失时间节点数量是 121\n",
      "qianmen_aq 缺失时间节点数量是 121\n",
      "donggaocun_aq 缺失时间节点数量是 121\n",
      "gucheng_aq 缺失时间节点数量是 121\n",
      "nansanhuan_aq 缺失时间节点数量是 121\n",
      "guanyuan_aq 缺失时间节点数量是 121\n",
      "dongsihuan_aq 缺失时间节点数量是 121\n",
      "nongzhanguan_aq 缺失时间节点数量是 121\n",
      "yizhuang_aq 缺失时间节点数量是 121\n",
      "yanqin_aq 缺失时间节点数量是 121\n",
      "miyun_aq 缺失时间节点数量是 121\n",
      "mentougou_aq 缺失时间节点数量是 122\n",
      "yufa_aq 缺失时间节点数量是 121\n",
      "aotizhongxin_aq 缺失时间节点数量是 122\n",
      "wanshouxigong_aq 缺失时间节点数量是 121\n",
      "zhiwuyuan_aq 缺失时间节点数量是 121\n",
      "tiantan_aq 缺失时间节点数量是 121\n",
      "huairou_aq 缺失时间节点数量是 121\n",
      "daxing_aq 缺失时间节点数量是 121\n",
      "miyunshuiku_aq 缺失时间节点数量是 121\n",
      "xizhimenbei_aq 缺失时间节点数量是 121\n",
      "tongzhou_aq 缺失时间节点数量是 121\n",
      "yungang_aq 缺失时间节点数量是 121\n",
      "dingling_aq 缺失时间节点数量是 121\n",
      "fengtaihuayuan_aq 缺失时间节点数量是 121\n",
      "pingchang_aq 缺失时间节点数量是 121\n",
      "yongledian_aq 缺失时间节点数量是 121\n",
      "pinggu_aq 缺失时间节点数量是 121\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    \n",
    "    min_time = df.index.min()\n",
    "    max_time = df.index.max()\n",
    "\n",
    "    min_time = datetime.datetime.strptime(min_time, '%Y-%m-%d %H:%M:%S')\n",
    "    max_time = datetime.datetime.strptime(max_time, '%Y-%m-%d %H:%M:%S')\n",
    "    delta_all = max_time - min_time\n",
    "    \n",
    "    all_length = delta_all.total_seconds()/3600 + 1\n",
    "    real_length = df.shape[0]\n",
    "    # print(\"在空气质量数据时间段内，总共应该有 %d 个小时节点。\" %(all_length))\n",
    "    # print(\"实际的时间节点数是 \", real_length)\n",
    "    print(\"%s 缺失时间节点数量是 %d\" %(station, all_length-real_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 整体缺失补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq (11351, 5)\n",
      "liulihe_aq (11351, 5)\n",
      "beibuxinqu_aq (11351, 5)\n",
      "badaling_aq (11351, 5)\n",
      "shunyi_aq (11351, 5)\n",
      "yongdingmennei_aq (11351, 5)\n",
      "fangshan_aq (11351, 5)\n",
      "wanliu_aq (11351, 5)\n",
      "qianmen_aq (11351, 5)\n",
      "donggaocun_aq (11351, 5)\n",
      "gucheng_aq (11351, 5)\n",
      "nansanhuan_aq (11351, 5)\n",
      "guanyuan_aq (11351, 5)\n",
      "dongsihuan_aq (11351, 5)\n",
      "nongzhanguan_aq (11351, 5)\n",
      "yizhuang_aq (11351, 5)\n",
      "yanqin_aq (11351, 5)\n",
      "miyun_aq (11351, 5)\n",
      "mentougou_aq (11350, 5)\n",
      "yufa_aq (11351, 5)\n",
      "aotizhongxin_aq (11350, 5)\n",
      "wanshouxigong_aq (11351, 5)\n",
      "zhiwuyuan_aq (11351, 5)\n",
      "tiantan_aq (11351, 5)\n",
      "huairou_aq (11351, 5)\n",
      "daxing_aq (11351, 5)\n",
      "miyunshuiku_aq (11351, 5)\n",
      "xizhimenbei_aq (11351, 5)\n",
      "tongzhou_aq (11351, 5)\n",
      "yungang_aq (11351, 5)\n",
      "dingling_aq (11351, 5)\n",
      "fengtaihuayuan_aq (11351, 5)\n",
      "pingchang_aq (11351, 5)\n",
      "yongledian_aq (11351, 5)\n",
      "pinggu_aq (11351, 5)\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    print(station, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq : length of data is 11472\n",
      "liulihe_aq : length of data is 11472\n",
      "beibuxinqu_aq : length of data is 11472\n",
      "badaling_aq : length of data is 11472\n",
      "shunyi_aq : length of data is 11472\n",
      "yongdingmennei_aq : length of data is 11472\n",
      "fangshan_aq : length of data is 11472\n",
      "wanliu_aq : length of data is 11472\n",
      "qianmen_aq : length of data is 11472\n",
      "donggaocun_aq : length of data is 11472\n",
      "gucheng_aq : length of data is 11472\n",
      "nansanhuan_aq : length of data is 11472\n",
      "guanyuan_aq : length of data is 11472\n",
      "dongsihuan_aq : length of data is 11472\n",
      "nongzhanguan_aq : length of data is 11472\n",
      "yizhuang_aq : length of data is 11472\n",
      "yanqin_aq : length of data is 11472\n",
      "miyun_aq : length of data is 11472\n",
      "mentougou_aq : length of data is 11472\n",
      "yufa_aq : length of data is 11472\n",
      "aotizhongxin_aq : length of data is 11472\n",
      "wanshouxigong_aq : length of data is 11472\n",
      "zhiwuyuan_aq : length of data is 11472\n",
      "tiantan_aq : length of data is 11472\n",
      "huairou_aq : length of data is 11472\n",
      "daxing_aq : length of data is 11472\n",
      "miyunshuiku_aq : length of data is 11472\n",
      "xizhimenbei_aq : length of data is 11472\n",
      "tongzhou_aq : length of data is 11472\n",
      "yungang_aq : length of data is 11472\n",
      "dingling_aq : length of data is 11472\n",
      "fengtaihuayuan_aq : length of data is 11472\n",
      "pingchang_aq : length of data is 11472\n",
      "yongledian_aq : length of data is 11472\n",
      "pinggu_aq : length of data is 11472\n"
     ]
    }
   ],
   "source": [
    "delta = datetime.timedelta(hours=1)\n",
    "\n",
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    nan_series = pd.Series({key:np.nan for key in df.columns})\n",
    "    \n",
    "    min_time = df.index.min()\n",
    "    max_time = df.index.max()\n",
    "\n",
    "    min_time = datetime.datetime.strptime(min_time, '%Y-%m-%d %H:%M:%S')\n",
    "    max_time = datetime.datetime.strptime(max_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    time = min_time\n",
    "    \n",
    "    while time <=  max_time :\n",
    "        \n",
    "        time_str = datetime.date.strftime(time, '%Y-%m-%d %H:%M:%S')\n",
    "        if time_str not in df.index :\n",
    "            \n",
    "            # 前边第几个是非空的\n",
    "            found_for = False\n",
    "            i = 0\n",
    "            while not found_for :\n",
    "                i += 1\n",
    "                for_time = time - i * delta\n",
    "                for_time_str = datetime.date.strftime(for_time, '%Y-%m-%d %H:%M:%S')\n",
    "                if for_time_str in df.index :\n",
    "                    for_row = df.loc[for_time_str]\n",
    "                    for_step = i\n",
    "                    found_for = True\n",
    "\n",
    "            # 后边第几个是非空的\n",
    "            found_back = False\n",
    "            j = 0\n",
    "            while not found_back :\n",
    "                j += 1\n",
    "                back_time = time + j * delta\n",
    "                back_time_str = datetime.date.strftime(back_time, '%Y-%m-%d %H:%M:%S')\n",
    "                if back_time_str in df.index :\n",
    "                    back_row = df.loc[back_time_str]\n",
    "                    back_step = j\n",
    "                    found_back = True\n",
    "        \n",
    "            all_steps = for_step + back_step\n",
    "        \n",
    "            if all_steps <= 5 :\n",
    "                delata_values = back_row - for_row\n",
    "                df.loc[time_str] = for_row + (for_step/all_steps) * delata_values\n",
    "            else :\n",
    "                df.loc[time_str] = nan_series\n",
    "        \n",
    "        time += delta\n",
    "    bj_meo_stations[station] = df\n",
    "    \n",
    "    print(\"%s : length of data is %d\" %(station, df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 风向缺失值处理\n",
    "- 暂时使用 0 替换缺失的风向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for station in bj_meo_stations.keys():\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    df.replace(999017,0, inplace=True)\n",
    "    bj_meo_stations[station] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 拼成整表，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged = pd.concat(list(bj_meo_stations.values()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11472, 175)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_meo_stations_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged.to_csv(\"data/bj_meo_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要将 `bj_meo_data.csv`左上角位置的空格补上 \"time\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe = bj_meo_stations_merged.describe()\n",
    "describe.to_csv(\"data/bj_meo_describe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_norm = (bj_meo_stations_merged - describe.loc['mean']) / describe.loc['std']\n",
    "df_norm.to_csv(\"data/bj_meo_norm_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "- 0425 v0\n",
    "    - 天气数据的缺失值补全\n",
    "    - 将数据保存到 `data/bj_meo_data.csv`中\n",
    "- 0426 v0.1\n",
    "    - 增加数据正则化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
