{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用之前5天的数据，对之后48小时的空气质量进行预测，模型如下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://p3rz3gu1u.bkt.clouddn.com/2018-04-19-seq2seq_model.png)\n",
    "<caption><center> **Figure 1**: lstm model</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvdev/tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "from utils.plot_util import plot_forecast_and_actual_example\n",
    "from metrics.metrics import SMAPE_on_dataset_v1\n",
    "from seq2seq.seq2seq_data_util import get_training_statistics, generate_training_set, generate_dev_set\n",
    "from seq2seq.multi_variable_seq2seq_model_parameters import build_graph\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "gpu_config = tf.ConfigProto()\n",
    "gpu_config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=gpu_config)\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多变量版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = ['dongsi_aq','tiantan_aq','guanyuan_aq','wanshouxigong_aq','aotizhongxin_aq',\n",
    "            'nongzhanguan_aq','wanliu_aq','beibuxinqu_aq','zhiwuyuan_aq','fengtaihuayuan_aq',\n",
    "            'yungang_aq','gucheng_aq','fangshan_aq','daxing_aq','yizhuang_aq','tongzhou_aq',\n",
    "            'shunyi_aq','pingchang_aq','mentougou_aq','pinggu_aq','huairou_aq','miyun_aq',\n",
    "            'yanqin_aq','dingling_aq','badaling_aq','miyunshuiku_aq','donggaocun_aq',\n",
    "            'yongledian_aq','yufa_aq','liulihe_aq','qianmen_aq','yongdingmennei_aq',\n",
    "            'xizhimenbei_aq','nansanhuan_aq','dongsihuan_aq']            \n",
    "X_aq_list = [\"PM2.5\",\"PM10\",\"O3\",\"CO\",\"SO2\",\"NO2\"]  \n",
    "y_aq_list = [\"PM2.5\",\"PM10\",\"O3\"]\n",
    "X_meo_list = [\"temperature\",\"pressure\",\"humidity\",\"direction\",\"speed/kph\"]\n",
    "use_day=True\n",
    "pre_days=5\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少变量版本（测试）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_list = ['aotizhongxin_aq']            \n",
    "# X_aq_list = [\"PM2.5\",\"PM10\",\"O3\",\"CO\",\"SO2\",\"NO2\"]  \n",
    "# y_aq_list = [\"PM2.5\"]\n",
    "# X_meo_list = [\"temperature\",\"pressure\",\"humidity\",\"direction\",\"speed/kph\"]\n",
    "# use_day = True\n",
    "# pre_days = 5\n",
    "# batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare test datasets in 3-D format - (batch_size, time_step, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = generate_dev_set(station_list=station_list,\n",
    "                                  X_aq_list=X_aq_list, \n",
    "                                  y_aq_list=y_aq_list, \n",
    "                                  X_meo_list=None,\n",
    "                                  pre_days=pre_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 120, 210) (17, 48, 105)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试生成一个训练样本，确保是我们想要的尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 120, 210) (128, 48, 105)\n"
     ]
    }
   ],
   "source": [
    "X_training_batch, y_training_batch = generate_training_set(station_list=station_list,\n",
    "                                                           X_aq_list=X_aq_list,\n",
    "                                                           y_aq_list=y_aq_list,\n",
    "                                                           pre_days=pre_days,\n",
    "                                                           X_meo_list=None,\n",
    "                                                           use_day=True,\n",
    "                                                           batch_size=batch_size)\n",
    "print(X_training_batch.shape, y_training_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build the model and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = pre_days * 24\n",
    "output_seq_len = 48\n",
    "hidden_dim = 512\n",
    "input_dim = 210\n",
    "output_dim = 105\n",
    "num_stacked_layers = 3\n",
    "\n",
    "learning_rate=1e-3\n",
    "lambda_l2_reg=0.003\n",
    "GRADIENT_CLIPPING=2.5\n",
    "total_iteractions = 1000\n",
    "KEEP_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = build_graph(feed_previous=False, \n",
    "                        input_seq_len=input_seq_len, \n",
    "                        output_seq_len=output_seq_len, \n",
    "                        hidden_dim=hidden_dim, \n",
    "                        input_dim=input_dim, \n",
    "                        output_dim=output_dim, \n",
    "                        num_stacked_layers=num_stacked_layers, \n",
    "                        learning_rate=learning_rate,\n",
    "                        lambda_l2_reg=lambda_l2_reg,\n",
    "                        GRADIENT_CLIPPING=GRADIENT_CLIPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training losses: \n",
      "loss after 0/1000 iteractions : 166.108\n",
      "loss after 10/1000 iteractions : 83.692\n",
      "loss after 20/1000 iteractions : 73.189\n",
      "loss after 30/1000 iteractions : 74.009\n",
      "loss after 40/1000 iteractions : 67.078\n",
      "loss after 50/1000 iteractions : 66.528\n",
      "loss after 60/1000 iteractions : 63.434\n",
      "loss after 70/1000 iteractions : 61.978\n",
      "loss after 80/1000 iteractions : 59.448\n",
      "loss after 90/1000 iteractions : 58.214\n",
      "loss after 100/1000 iteractions : 56.989\n",
      "loss after 110/1000 iteractions : 55.477\n",
      "loss after 120/1000 iteractions : 54.328\n",
      "loss after 130/1000 iteractions : 52.780\n",
      "loss after 140/1000 iteractions : 51.625\n",
      "loss after 150/1000 iteractions : 50.542\n",
      "loss after 160/1000 iteractions : 49.364\n",
      "loss after 170/1000 iteractions : 48.164\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    losses = []\n",
    "    print(\"Training losses: \")\n",
    "    for i in range(total_iteractions):\n",
    "        batch_input, batch_output = generate_training_set(station_list,\n",
    "                                                          X_aq_list,\n",
    "                                                          y_aq_list,\n",
    "                                                          X_meo_list=None,\n",
    "                                                          use_day=use_day,\n",
    "                                                          pre_days=pre_days,\n",
    "                                                          batch_size=batch_size)\n",
    "\n",
    "        \n",
    "        feed_dict = {rnn_model['enc_inp'][t]: batch_input[:,t,:] for t in range(input_seq_len)}\n",
    "        feed_dict.update({rnn_model['target_seq'][t]: batch_output[:,t,:] for t in range(output_seq_len)})\n",
    "        _, loss_t = sess.run([rnn_model['train_op'], rnn_model['loss']], feed_dict) \n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(\"loss after %d/%d iteractions : %.3f\" %(i, total_iteractions, loss_t))\n",
    "            \n",
    "            # 想要对训练过程中训练集的 smape 进行监督，发现模型并不是处在“预测”的状态，因此放弃\n",
    "            # train_preds = sess.run(rnn_model['reshaped_outputs'], feed_dict)\n",
    "            # train_preds = [np.expand_dims(pred, 1) for pred in train_preds]\n",
    "            # train_preds = np.concatenate(train_preds, axis = 1)\n",
    "            \n",
    "        losses.append(loss_t)\n",
    "        \n",
    "    temp_saver = rnn_model['saver']()\n",
    "    save_path = temp_saver.save(sess, os.path.join('./seq2seq/new_multi_variable_model_results/', 'multivariate_ts_pollution_case'))\n",
    "        \n",
    "print(\"Checkpoint saved at: \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on test \n",
    "Notice the batch prediction which is different to previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = build_graph(feed_previous=True, \n",
    "                        input_seq_len=input_seq_len, \n",
    "                        output_seq_len=output_seq_len, \n",
    "                        hidden_dim=hidden_dim, \n",
    "                        input_dim=input_dim, \n",
    "                        output_dim=output_dim, \n",
    "                        num_stacked_layers=num_stacked_layers, \n",
    "                        learning_rate=learning_rate,\n",
    "                        lambda_l2_reg=lambda_l2_reg,\n",
    "                        GRADIENT_CLIPPING=GRADIENT_CLIPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver = rnn_model['saver']().restore(sess,  os.path.join('./seq2seq/new_multi_variable_model_results/', 'multivariate_ts_pollution_case'))\n",
    "    \n",
    "    feed_dict = {rnn_model['enc_inp'][t]: test_x[:, t, :] for t in range(input_seq_len)} # batch prediction\n",
    "    feed_dict.update({rnn_model['target_seq'][t]: np.zeros([test_x.shape[0], output_dim], dtype=np.float32) for t in range(output_seq_len)})\n",
    "    final_preds = sess.run(rnn_model['reshaped_outputs'], feed_dict)\n",
    "    \n",
    "    final_preds = [np.expand_dims(pred, 1) for pred in final_preds]\n",
    "    final_preds = np.concatenate(final_preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of predictions is \",final_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of many featutres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features = []\n",
    "for station in station_list : \n",
    "    for aq_feature in y_aq_list :\n",
    "        output_features.append(station + \"_\" + aq_feature)\n",
    "\n",
    "# 特征要和训练时候的特征顺序保持一致\n",
    "output_features.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_features)\n",
    "print(\"Number of features is : \", len(output_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 预测值普遍在 O3 上表现较好，另外两个参数　PM2.5 和　PM10 上通常捕捉不到高频分量\n",
    "for i in range(len(output_features)):\n",
    "    plot_forecast_and_actual_example(test_x, test_y, final_preds, output_features, index=0, feature_index=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 某个特征在整个dev数据集时间跨度上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 0\n",
    "test_y_expand = np.concatenate([test_y[i,:,feature_index] for i in range(0, test_y.shape[0])], axis = 0)\n",
    "final_preds_expand = np.concatenate([final_preds[i,:,feature_index] for i in range(0, final_preds.shape[0])], axis = 0)\n",
    "plt.plot(final_preds_expand, color = 'orange', label = 'predicted')\n",
    "plt.plot(test_y_expand, color = 'blue', label = 'actual')\n",
    "plt.title(\"test data - one month\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smapes of all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入训练样本的统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = get_training_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算 smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aver_smapes, smapes_of_features = SMAPE_on_dataset_v1(test_y, final_preds, output_features, statistics, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape value on all features\n",
    "smapes_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average smape on all features in the dev set is : \",aver_smapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ChangeLog\n",
    "- 0427 v0\n",
    "    - 完成了第一版本模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
